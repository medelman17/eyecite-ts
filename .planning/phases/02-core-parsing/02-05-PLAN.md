---
phase: 02-core-parsing
plan: 05
type: execute
wave: 3
depends_on: [02-03, 02-04]
files_modified:
  - src/extract/extractCase.ts
  - src/extract/extractStatute.ts
  - src/extract/extractJournal.ts
  - src/extract/extractNeutral.ts
  - src/extract/extractPublicLaw.ts
  - src/extract/extractFederalRegister.ts
  - src/extract/index.ts
  - tests/extract/extractCase.test.ts
  - tests/extract/extractStatute.test.ts
autonomous: true

must_haves:
  truths:
    - "Developer can extract case citations from tokens with volume, reporter, page metadata"
    - "Developer can extract statute citations with code and section metadata"
    - "Developer can extract journal, neutral, public law, and federal register citations"
    - "All citations include confidence scores and matched text"
  artifacts:
    - path: "src/extract/extractCase.ts"
      provides: "Case citation metadata extraction"
      exports: ["extractCase"]
      min_lines: 60
    - path: "src/extract/extractStatute.ts"
      provides: "Statute citation metadata extraction"
      exports: ["extractStatute"]
      min_lines: 40
    - path: "tests/extract/extractCase.test.ts"
      provides: "Case extraction validation"
      min_lines: 50
  key_links:
    - from: "src/extract/extractCase.ts"
      to: "src/tokenize/tokenizer.ts"
      via: "Token input"
      pattern: "import.*Token.*from.*tokenize"
    - from: "src/extract/extractCase.ts"
      to: "src/types/citation.ts"
      via: "Citation output"
      pattern: "import.*Citation.*from.*types"
---

<objective>
Implement citation extraction layer that converts tokens into typed Citation objects with metadata. Extraction parses token text to extract volume, reporter, page, court, date, and other metadata fields. Includes confidence scoring and ambiguity handling.

Purpose: Converts tokenizer output into structured citations with rich metadata
Output: Extraction functions for all citation types, metadata parsing tests
</objective>

<execution_context>
@/Users/medelman/.claude/get-shit-done/workflows/execute-plan.md
@/Users/medelman/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-core-parsing/02-CONTEXT.md
@.planning/phases/02-core-parsing/02-RESEARCH.md
@.planning/phases/02-core-parsing/02-03-SUMMARY.md
@.planning/phases/02-core-parsing/02-04-SUMMARY.md
@src/types/citation.ts
@src/tokenize/tokenizer.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Implement case citation extraction with metadata parsing</name>
  <files>src/extract/extractCase.ts, src/extract/index.ts</files>
  <action>
Create `src/extract/extractCase.ts` with:

```typescript
import type { Token } from '@/tokenize'
import type { FullCaseCitation } from '@/types/citation'
import type { TransformationMap } from '@/types/span'

export function extractCase(
  token: Token,
  transformationMap: TransformationMap
): FullCaseCitation
```

Implementation:
1. Parse token.text to extract metadata using regex capture groups:
   - Volume: `(\d+)` at start
   - Reporter: `([A-Za-z\.\s]+)` in middle
   - Page: `(\d+)` after reporter
   - Example: "500 F.2d 123" → { volume: 500, reporter: "F.2d", page: 123 }

2. Extract optional metadata if present:
   - Pincite: Match `, (\d+)` after page (e.g., "500 F.2d 123, 125")
   - Court: Match `\(([^)]+)\)` for court abbreviation (e.g., "(9th Cir.)")
   - Year: Match `\((\d{4})\)` for year (e.g., "(2020)")

3. Translate positions using transformationMap:
   - Convert token.span.cleanStart → originalStart via transformationMap.cleanToOriginal
   - Convert token.span.cleanEnd → originalEnd via transformationMap.cleanToOriginal

4. Calculate confidence:
   - Start with 0.5 base
   - If reporter matches common pattern (F., U.S., etc.): +0.3
   - If year is valid (not future): +0.2
   - Cap at 1.0

5. Return FullCaseCitation with all metadata:
   - text: token.text
   - span: { cleanStart, cleanEnd, originalStart, originalEnd }
   - confidence: calculated score
   - matchedText: token.text
   - volume, reporter, page, pincite, court, year
   - processTimeMs: 0 (placeholder)
   - patternsChecked: 1

Create `src/extract/index.ts` with re-exports: `export * from "./extractCase"`.

**Note:** For Phase 2, extraction does NOT validate against reporters-db (that's Phase 3). Extraction only parses structure. Confidence scoring is simple heuristics.

Add JSDoc explaining metadata extraction and confidence calculation.
  </action>
  <verify>
Run `npm run typecheck` - no errors
Check that extractCase() is exported from src/extract/index.ts
Verify function returns FullCaseCitation type
  </verify>
  <done>extractCase() function parses case citation metadata from tokens with confidence scoring</done>
</task>

<task type="auto">
  <name>Task 2: Implement statute, journal, neutral, public law, and federal register extraction</name>
  <files>src/extract/extractStatute.ts, src/extract/extractJournal.ts, src/extract/extractNeutral.ts, src/extract/extractPublicLaw.ts, src/extract/extractFederalRegister.ts, src/extract/index.ts</files>
  <action>
Create extraction functions for remaining citation types:

**extractStatute.ts:**
```typescript
export function extractStatute(
  token: Token,
  transformationMap: TransformationMap
): StatuteCitation
```
- Parse: `(\d+)\s+([A-Za-z\.\s]+)\s+§\s*(\d+)` → { title, code, section }
- Example: "42 U.S.C. § 1983" → { title: 42, code: "U.S.C.", section: "1983" }
- Extract optional subsections: § 1983(a)(1) → subsections: ["a", "1"]
- Confidence: 0.8 if code matches known pattern, else 0.5

**extractJournal.ts:**
```typescript
export function extractJournal(
  token: Token,
  transformationMap: TransformationMap
): JournalCitation
```
- Parse: `(\d+)\s+([A-Za-z\.\s]+)\s+(\d+)` → { volume, journal, page }
- Example: "123 Harv. L. Rev. 456" → { volume: 123, journal: "Harv. L. Rev.", page: 456 }
- Extract optional author from preceding text (look back in original for "Name,")
- Confidence: 0.6 (journal validation happens in Phase 3)

**extractNeutral.ts:**
```typescript
export function extractNeutral(
  token: Token,
  transformationMap: TransformationMap
): NeutralCitation
```
- Parse: `(\d{4})\s+(WL|LEXIS)\s+(\d+)` → { year, court, documentNumber }
- Example: "2020 WL 123456" → { year: 2020, court: "WL", documentNumber: "123456" }
- Confidence: 1.0 (neutral format is unambiguous)

**extractPublicLaw.ts:**
```typescript
export function extractPublicLaw(
  token: Token,
  transformationMap: TransformationMap
): PublicLawCitation
```
- Parse: `Pub\.\s?L\.\s?No\.\s?(\d+)-(\d+)` → { congress, lawNumber }
- Example: "Pub. L. No. 116-283" → { congress: 116, lawNumber: 283 }
- Confidence: 0.9 (public law format is fairly standard)

**extractFederalRegister.ts:**
```typescript
export function extractFederalRegister(
  token: Token,
  transformationMap: TransformationMap
): FederalRegisterCitation
```
- Parse: `(\d+)\s+Fed\.\s?Reg\.\s+(\d+)` → { volume, page }
- Example: "85 Fed. Reg. 12345" → { volume: 85, page: 12345 }
- Confidence: 0.9

All functions follow same pattern:
1. Parse token.text with regex
2. Translate positions via transformationMap
3. Calculate confidence score
4. Return typed Citation object

Update `src/extract/index.ts` to re-export all extraction functions.

Add JSDoc for each function explaining format and metadata fields.
  </action>
  <verify>
Run `npm run typecheck` - no errors
Check that all extraction functions are exported from src/extract/index.ts
Verify each function returns correct Citation type
  </verify>
  <done>Extraction functions for all citation types (statute, journal, neutral, public law, federal register) with metadata parsing</done>
</task>

<task type="auto">
  <name>Task 3: Test citation extraction and metadata accuracy</name>
  <files>tests/extract/extractCase.test.ts, tests/extract/extractStatute.test.ts</files>
  <action>
Create `tests/extract/extractCase.test.ts` with Vitest tests:

**Test 1: Extract volume-reporter-page**
- Token: { text: "500 F.2d 123", ... }
- Expected: { volume: 500, reporter: "F.2d", page: 123, confidence >= 0.5 }
- Assert: Metadata fields match expected values

**Test 2: Extract case with pincite**
- Token: { text: "500 F.2d 123, 125", ... }
- Expected: { volume: 500, reporter: "F.2d", page: 123, pincite: 125 }
- Assert: Pincite extracted correctly

**Test 3: Extract case with court and year**
- Token: { text: "500 F.2d 123 (9th Cir. 2020)", ... }
- Expected: { court: "9th Cir.", year: 2020 }
- Assert: Court and year extracted from parenthetical

**Test 4: Position translation**
- Token with clean positions: { cleanStart: 10, cleanEnd: 23 }
- TransformationMap maps clean → original (e.g., cleanStart: 10 → originalStart: 12)
- Expected: Citation span includes both clean and original positions
- Assert: originalStart/originalEnd correctly translated from cleanStart/cleanEnd

**Test 5: Confidence scoring**
- Token with well-formed case: confidence >= 0.8
- Token with unknown reporter: confidence < 0.8
- Assert: Confidence reflects match quality

Create `tests/extract/extractStatute.test.ts` with similar tests for statute extraction (code + section parsing).

Mock TransformationMap for testing: simple 1:1 mapping for most tests, offset mapping for position translation test.

Use descriptive test names and assert all metadata fields.
  </action>
  <verify>
Run `npm test tests/extract/` - all extraction tests pass
Test coverage for src/extract/ >= 80%
Verify metadata parsing is accurate for all citation types
  </verify>
  <done>Extraction tests pass, validating metadata accuracy and position translation</done>
</task>

</tasks>

<verification>
1. Run `npm run typecheck` - no TypeScript errors
2. Run `npm test tests/extract/` - all extraction tests pass
3. Check that all extraction functions handle metadata parsing
4. Verify confidence scores are calculated for all citation types
5. Test coverage >= 80% for src/extract/ directory
</verification>

<success_criteria>
- Developer can extract case citations with volume, reporter, page, pincite, court, year metadata
- Developer can extract statute citations with code, section, subsection metadata
- Developer can extract journal, neutral, public law, and federal register citations
- All citations include confidence scores based on match quality
- Position translation via TransformationMap is accurate
- All code compiles with TypeScript strict mode
</success_criteria>

<output>
After completion, create `.planning/phases/02-core-parsing/02-05-SUMMARY.md`
</output>
